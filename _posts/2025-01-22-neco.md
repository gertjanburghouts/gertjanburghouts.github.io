---
layout: post
title: "Improving DINO v2's Scene Understanding"
date: 2025-01-22 08:00:00 -0000
categories: self-supervised learning transformer patches ordering consistency
excerpt_separator: <!--more-->
---

DINO v2 extracts strong features from an image at the patch level. 
However, it is not very consistent across images, e.g. it does not yield the same features for the tip of a finger across various people in different images. 
We aimed to improve this, by a self-supervised learning strategy. 

Our strategy aims to improve the consistency, by enforcing that the patches in two views of the same image (i.e. different augmentations) follow the same ordering. 
This ordering proves to be a very strong learning signal: it is much stronger than just looking at the nearest neighbors only, or looking at clusters of patches in embedding space.
Compared to contrastive approaches that only yield binary learning signals, i.e. "attract" and "repel", 
this approach benefits from the more fine-grained learning signal of sorting spatially dense features relative to reference patches. 

We call our method NeCo: Patch Neighbor Consistency. 

<img src="https://gertjanburghouts.github.io/pictures/NeCo.jpg">

We establish several new state-of-the-art results such as +5.5 % and +6% for non-parametric in-context semantic segmentation on 
ADE20k and Pascal VOC, +7.2% and +5.7% for linear segmentation evaluations on COCO-Things and -Stuff and improvements in the 3D understanding of multi-view consistency on SPair-71k, by more than 10%. 

<img src="https://gertjanburghouts.github.io/pictures/NeCo_performance.jpg">

Its features are much more consistent across images and categories. 
E.g., it yields the same features for the tip of a finger across various people in different images. 

<img src="https://gertjanburghouts.github.io/pictures/NeCo_results.jpg">

Accepted at International Conference on Learning Representations (ICLR) 2025. See publications.
